<h1 id="Persistent-Read-Side"><a class="section-marker" href="#Persistent-Read-Side">§</a>Persistent Read-Side</h1><p><a href="ES_CQRS.html">Event Sourcing and CQRS</a> is a recommended introduction to this section.</p><p><a href="PersistentEntity.html">Persistent Entities</a> are used for holding the state of individual entities, but they cannot be used for serving queries that span more than one entity. You need to know the identifier of the entity to be able to interact with it. Therefore you need to create another view of the data that is tailored to the queries that the service provides. Lagom has support for populating this read-side view of the data and also for building queries of the read-side.</p><p>This separation of the write-side and the read-side of the persistent data is often referred to as the <a href="https://msdn.microsoft.com/en-us/library/jj591573.aspx">CQRS</a> (Command Query Responibility Segregation) pattern. The <a href="https://msdn.microsoft.com/en-us/library/jj554200.aspx">CQRS Journey</a> is a great resource for learning more about CQRS.</p><h2 id="Dependency"><a class="section-marker" href="#Dependency">§</a>Dependency</h2><p>To use this feature add the following in your project&rsquo;s build:</p>
<pre class="prettyprint"><code class="language-sbt">libraryDependencies += lagomJavadslPersistence</code></pre><h2 id="Query-the-Read-Side-Database"><a class="section-marker" href="#Query-the-Read-Side-Database">§</a>Query the Read-Side Database</h2><p>Lagom has support for <a href="http://cassandra.apache.org/">Cassandra</a> as data store, both for the write-side entities and the read-side queries. It is a very scalable distributed database, and also flexible enough to support most of the use cases that reactive services may have.</p><p>Let us first look at how a service implementation can retrieve data from Cassandra.</p>
<pre class="prettyprint"><code class="language-java">import akka.NotUsed;
import com.lightbend.lagom.javadsl.api.ServiceCall;
import com.lightbend.lagom.javadsl.persistence.cassandra.CassandraSession;
import java.util.concurrent.CompletableFuture;
import javax.inject.Inject;
import akka.stream.javadsl.Source;

public class BlogServiceImpl2 implements BlogService2 {

  private final CassandraSession cassandraSession;

  @Inject
  public BlogServiceImpl2(CassandraSession cassandraSession) {
    this.cassandraSession = cassandraSession;
  }

  @Override
  public ServiceCall&lt;NotUsed, NotUsed, Source&lt;PostSummary, ?&gt;&gt; getPostSummaries() {
    return (id, request) -&gt; {
      Source&lt;PostSummary, ?&gt; summaries = cassandraSession.select(
          &quot;SELECT id, title FROM postsummary;&quot;).map(row -&gt;
            PostSummary.of(row.getString(&quot;id&quot;), row.getString(&quot;title&quot;)));
      return CompletableFuture.completedFuture(summaries);
    };
  }
}</code></pre><p>Note that the <a href="api/java/index.html?com/lightbend/lagom/javadsl/persistence/cassandra/CassandraSession.html">CassandraSession</a> is injected in the constructor. <code>CassandraSession</code> provides several methods in different flavors for executing queries. The one used in the above example returns a <code>Source</code>, i.e. a streamed response. There are also methods for retrieving a list of rows, which can be useful when you know that the result set is small, e.g. when you have included a <code>LIMIT</code> clause.</p><p>All methods in <code>CassandraSession</code> are non-blocking and they return a <code>CompletionStage</code> or a <code>Source</code>. The statements are expressed in <a href="http://docs.datastax.com/en/cql/3.3/cql/cqlIntro.html">Cassandra Query Language</a> (CQL) syntax. See <a href="http://docs.datastax.com/en/cql/3.3/cql/cql_using/useQueryDataTOC.html">Querying tables</a> for information about CQL queries.</p><h2 id="Update-the-Read-Side"><a class="section-marker" href="#Update-the-Read-Side">§</a>Update the Read-Side</h2><p>We need to transform the events generated by the <a href="PersistentEntity.html">Persistent Entities</a> into database tables that can be queried as illustrated in the previous section. For that we will use the <a href="api/java/index.html?com/lightbend/lagom/javadsl/persistence/cassandra/CassandraReadSideProcessor.html">CassandraReadSideProcessor</a>. It will Consume events produced by persistent entities and update one or more tables in Cassandra that are optimized for queries.</p><p>This is how a <a href="api/java/index.html?com/lightbend/lagom/javadsl/persistence/cassandra/CassandraReadSideProcessor.html">CassandraReadSideProcessor</a> class looks like before filling in the implementation details:</p>
<pre class="prettyprint"><code class="language-java">import com.lightbend.lagom.javadsl.persistence.AggregateEventTag;

import com.lightbend.lagom.javadsl.persistence.cassandra.CassandraReadSideProcessor;
import com.lightbend.lagom.javadsl.persistence.cassandra.CassandraSession;
import java.util.Optional;
import java.util.UUID;
import java.util.concurrent.CompletionStage;

public class BlogEventProcessor1 extends CassandraReadSideProcessor&lt;BlogEvent&gt; {

  @Override
  public AggregateEventTag&lt;BlogEvent&gt; aggregateTag() {
    // TODO return the tag for the events
    return null;
  }

  @Override
  public CompletionStage&lt;Optional&lt;UUID&gt;&gt; prepare(CassandraSession session) {
    // TODO prepare statements, fetch offset
    return noOffset();
  }

  @Override
  public EventHandlers defineEventHandlers(EventHandlersBuilder builder) {
    // TODO define event handlers
    return builder.build();
  }

}</code></pre><p>To make the events available for read-side processing the events must implement the <code>aggregateTag</code> method of the <a href="api/java/index.html?com/lightbend/lagom/javadsl/persistence/AggregateEvent.html">AggregateEvent</a> interface to define which events belong together. Typically you define this <code>aggregateTag</code> on the top level event type of a <code>PersistentEntity</code> class.</p><p>The <a href="api/java/index.html?com/lightbend/lagom/javadsl/persistence/AggregateEventTag.html">AggregateEventTag</a> for the <code>BlogEvent</code> is defined as a constant like this:</p>
<pre class="prettyprint"><code class="language-java">public class BlogEventTag {

  public static final AggregateEventTag&lt;BlogEvent&gt; INSTANCE =
    AggregateEventTag.of(BlogEvent.class);

}</code></pre><p>The <code>BlogEvent</code> classes:</p>
<pre class="prettyprint"><code class="language-java">interface BlogEvent extends Jsonable, AggregateEvent&lt;BlogEvent&gt; {

  @Override
  default public AggregateEventTag&lt;BlogEvent&gt; aggregateTag() {
    return BlogEventTag.INSTANCE;
  }

  @Value.Immutable
  @ImmutableStyle
  @JsonDeserialize(as = PostAdded.class)
  interface AbstractPostAdded extends BlogEvent {
    String getPostId();

    PostContent getContent();
  }

  @Value.Immutable
  @ImmutableStyle
  @JsonDeserialize(as = BodyChanged.class)
  interface AbstractBodyChanged extends BlogEvent {
    @Value.Parameter
    String getBody();
  }

  @Value.Immutable
  @ImmutableStyle
  @JsonDeserialize(as = PostPublished.class)
  interface AbstractPostPublished extends BlogEvent {
    @Value.Parameter
    String getPostId();
  }

}</code></pre><p>In the service implementation you need to inject the <a href="api/java/index.html?com/lightbend/lagom/javadsl/persistence/cassandra/CassandraReadSide.html">CassandraReadSide</a> and at startup (in the constructor) register the class that implements the <code>CassandraReadSideProcessor</code>. This will make sure that one instance of the processor is always running on one of the nodes in the cluster of the service.</p>
<pre class="prettyprint"><code class="language-java">@Inject
public BlogServiceImpl3(
    PersistentEntityRegistry persistentEntityRegistry,
    CassandraSession cassandraSession,
    CassandraReadSide cassandraReadSide) {

  this.persistentEntityRegistry = persistentEntityRegistry;
  this.cassandraSession = cassandraSession;

  cassandraReadSide.register(BlogEventProcessor.class);
}</code></pre><h3 id="aggregateTag"><a class="section-marker" href="#aggregateTag">§</a>aggregateTag</h3><p>Define the <a href="api/java/index.html?com/lightbend/lagom/javadsl/persistence/AggregateEventTag.html">AggregateEventTag</a> in the method <code>aggregateTag</code> of the processor. The tag defines which events to process. You should return the same constant value as in the events.</p>
<pre class="prettyprint"><code class="language-java">@Override
public AggregateEventTag&lt;BlogEvent&gt; aggregateTag() {
  return BlogEventTag.INSTANCE;
}</code></pre><h3 id="prepare"><a class="section-marker" href="#prepare">§</a>prepare</h3><p>You must tell where in the event stream the processing should start. This is the primary purpose of the <code>prepare</code> method. Each event is associated with a unique offset, a time based UUID. The offset is a parameter to the event handler for each event and it should typically be stored so that it can be retrieved with a <code>select</code> statement in the <code>prepare</code> method. Use the <code>CassandraSession</code> to get the stored offset.</p>
<pre class="prettyprint"><code class="language-java">private CompletionStage&lt;Optional&lt;UUID&gt;&gt; selectOffset(CassandraSession session) {
  return session.selectOne(&quot;SELECT offset FROM blogevent_offset&quot;).thenApply(
      optionalRow -&gt; optionalRow.map(r -&gt; r.getUUID(&quot;offset&quot;)));
}</code></pre><p>Return <code>noOffset()</code> if you want to processes all events, e.g. when starting the first time or if the number of events are known to be small enough to processes all events.</p><p>Typically <code>prepare</code> is also used to create prepared statements that are later used when processing the events. Use <code>CassandraSession.prepare</code> to create the prepared statements.</p>
<pre class="prettyprint"><code class="language-java">private PreparedStatement writeTitle = null; // initialized in prepare
private PreparedStatement writeOffset = null; // initialized in prepare

private void setWriteTitle(PreparedStatement writeTitle) {
  this.writeTitle = writeTitle;
}

private void setWriteOffset(PreparedStatement writeOffset) {
  this.writeOffset = writeOffset;
}

private CompletionStage&lt;NotUsed&gt; prepareWriteTitle(CassandraSession session) {
  return session.prepare(&quot;INSERT INTO blogsummary (partition, id, title) VALUES (1, ?, ?)&quot;)
      .thenApply(ps -&gt; {
        setWriteTitle(ps);
        return NotUsed.getInstance();
      });
}

private CompletionStage&lt;NotUsed&gt; prepareWriteOffset(CassandraSession session) {
  return session.prepare(&quot;INSERT INTO blogevent_offset (partition, offset) VALUES (1, ?)&quot;)
      .thenApply(ps -&gt; {
        setWriteOffset(ps);
        return NotUsed.getInstance();
      });
}</code></pre><p>Composing those asynchronous <code>CompletionStage</code> tasks may look like this:</p>
<pre class="prettyprint"><code class="language-java">@Override
public CompletionStage&lt;Optional&lt;UUID&gt;&gt; prepare(CassandraSession session) {
  return
    prepareWriteTitle(session).thenCompose(a -&gt;
    prepareWriteOffset(session).thenCompose(b -&gt;
    selectOffset(session)));
}</code></pre><h3 id="defineEventHandlers"><a class="section-marker" href="#defineEventHandlers">§</a>defineEventHandlers</h3><p>The events are processed by event handlers that are defined in the method <code>defineEventHandlers</code>. One handler for each event class.</p><p>A handler is a <code>BiFunction</code> that takes the event and the offset as parameters and returns zero or more bound statements that will be executed before processing next event.</p>
<pre class="prettyprint"><code class="language-java">@Override
public EventHandlers defineEventHandlers(EventHandlersBuilder builder) {
  builder.setEventHandler(PostAdded.class, this::processPostAdded);
  return builder.build();
}

private CompletionStage&lt;List&lt;BoundStatement&gt;&gt; processPostAdded(PostAdded event, UUID offset) {
  BoundStatement bindWriteTitle = writeTitle.bind();
  bindWriteTitle.setString(&quot;id&quot;, event.getPostId());
  bindWriteTitle.setString(&quot;title&quot;, event.getContent().getTitle());
  BoundStatement bindWriteTitleOffset = writeOffset.bind(offset);
  return completedStatements(Arrays.asList(bindWriteTitle, bindWriteTitleOffset));
}</code></pre><p>In this example we add one row to the <code>blogsummary</code> table and update the current offset in the <code>blogevent_offset</code> table for each <code>PostAdded</code> event. Other event types are ignored.</p><p>Note how the prepared statements that were initialized in the <code>prepare</code> method are used here.</p><p>You can keep state in variables of the enclosing class and update that state safely from the event handlers. The events are processed sequentially, one at a time. An example of such state could be values for calculating a moving average.</p><p>If there is a failure when executing the statements the processor will be restarted after a backoff delay. This delay is increased exponentially in case of repeated failures.</p><h2 id="Raw-Stream-of-Events"><a class="section-marker" href="#Raw-Stream-of-Events">§</a>Raw Stream of Events</h2><p>There is another tool that can be used if you want to do something else with the events than updating tables in Cassandra. You can get a stream of the persistent events with the <code>eventStream</code> method of the <a href="api/java/index.html?com/lightbend/lagom/javadsl/persistence/PersistentEntityRegistry.html">PersistentEntityRegistry</a>.</p>
<pre class="prettyprint"><code class="language-java">public ServiceCall&lt;NotUsed, NotUsed, Source&lt;PostSummary, ?&gt;&gt; newPosts() {
  final PartialFunction&lt;BlogEvent, PostSummary&gt; collectFunction =
      new PFBuilder&lt;BlogEvent, PostSummary&gt;()
      .match(PostAdded.class, evt -&gt;
         PostSummary.of(evt.getPostId(), evt.getContent().getTitle()))
      .build();

  return (id, request) -&gt; {
    Source&lt;PostSummary, ?&gt; stream = persistentEntityRegistry
      .eventStream(BlogEventTag.INSTANCE, Optional.empty())
        .map(pair -&gt; pair.first()).collect(collectFunction);
    return CompletableFuture.completedFuture(stream);
  };
}</code></pre><p>The <code>eventStream</code> method takes the event class that implements the <code>AggregateEventType</code> and an optional offset, which is the starting point of the stream. It returns a <code>Source</code> of <code>Pair</code> elements, which contains the event and the associated offset.</p><p>This stream will never complete, unless there is failure from retrieving the events from the database. It will continue to deliver new events as they are persisted.</p><p>Each such stream of events will continuously generate queries to Cassandra to fetch new events and therefore this tool should be used carefully. Do not run too many such streams. It should typically not be used for service calls invoked by unknown number of clients, but it can be useful for a limited number of background processing jobs.</p><h2 id="Refactoring-Consideration"><a class="section-marker" href="#Refactoring-Consideration">§</a>Refactoring Consideration</h2><p>If you use a class name of a event type as the aggregate tag in <a href="api/java/index.html?com/lightbend/lagom/javadsl/persistence/AggregateEventTag.html">AggregateEventTag</a> you have to retain the original tag if you change the event class name because this string is part of the stored event data. <code>AggregateEventTag</code> has a factory method (and constructor) with a <code>String tag</code> parameter for this purpose. Instead of using a class name as tag identifier you can consider to use a string tag up-front. The tag should be unique among the event types of the service.</p><h2 id="Configuration"><a class="section-marker" href="#Configuration">§</a>Configuration</h2><p>The default configuration should be good starting point, and the following settings may later be amended to customize the behavior if needed.</p>
<pre class="prettyprint"><code class="language-conf">lagom.persistence.read-side {

  cassandra {
  
    # Comma-separated list of contact points in the Cassandra cluster
    contact-points = [&quot;127.0.0.1&quot;]
  
    # Port of contact points in the Cassandra cluster
    port = ${lagom.defaults.persistence.read-side.cassandra.port}
    
    # The implementation of akka.persistence.cassandra.SessionProvider
    # is used for creating the Cassandra Session. By default the 
    # the ServiceLocatorSessionProvider is building the Cluster from configuration 
    # and contact points are looked up with ServiceLocator using the configured
    # cluster-id as the service name.
    # Use akka.persistence.cassandra.ConfigSessionProvider to read the contact-points
    # from configuration instead of using the ServiceLocator.
    # It is possible to replace the implementation of the SessionProvider
    # to reuse another session or override the Cluster builder with other
    # settings.
    # The implementation class may optionally have a constructor with an ActorSystem 
    # and Config parameter. The config parameter is the enclosing config section.
    session-provider = com.lightbend.lagom.internal.persistence.cassandra.ServiceLocatorSessionProvider
    
    # The identifier that will be passed as parameter to the
    # ServiceLocatorSessionProvider.lookupContactPoints method. 
    cluster-id = &quot;cas_native&quot;
    cluster-id = ${?CASSANDRA_SERVICE_NAME}
    
    # Write consistency level
    write-consistency = &quot;QUORUM&quot;

    # Read consistency level
    read-consistency = &quot;QUORUM&quot;
    
    # The name of the Cassandra keyspace 
    keyspace = ${lagom.defaults.persistence.read-side.cassandra.keyspace}
  
    # Parameter indicating whether the journal keyspace should be auto created
    keyspace-autocreate = true
    
    # replication strategy to use when creating keyspace. 
    # SimpleStrategy or NetworkTopologyStrategy
    replication-strategy = &quot;SimpleStrategy&quot;
    
    # Replication factor to use when creating keyspace. 
    # Is only used when replication-strategy is SimpleStrategy.
    replication-factor = 1
    
    # Replication factor list for data centers, e.g. [&quot;dc1:3&quot;, &quot;dc2:2&quot;]. 
    # Is only used when replication-strategy is NetworkTopologyStrategy.
    data-center-replication-factors = []
    
    # To limit the Cassandra hosts that it connects to a specific datacenter.
    # (DCAwareRoundRobinPolicy withLocalDc)
    # The id for the local datacenter of the Cassandra hosts it should connect to. 
    # By default, this property is not set resulting in Datastax&#39;s standard round robin policy being used.
    local-datacenter = &quot;&quot;
  
    # To connect to the Cassandra hosts with credentials.
    # Authentication is disabled if username is not configured.
    authentication.username = &quot;&quot;
    authentication.password = &quot;&quot;
  
    # SSL can be configured with the following properties.
    # SSL is disabled if the truststore is not configured.
    # For detailed instructions, please refer to the DataStax Cassandra chapter about 
    # SSL Encryption: http://docs.datastax.com/en/cassandra/2.0/cassandra/security/secureSslEncryptionTOC.html
    # Path to the JKS Truststore file 
    ssl.truststore.path = &quot;&quot;
    # Password to unlock the JKS Truststore
    ssl.truststore.password = &quot;&quot;
    # Path to the JKS Keystore file (optional config, only needed for client authentication)
    ssl.keystore.path = &quot;&quot;
    # Password to unlock JKS Truststore and access the private key (both must use the same password)
    ssl.keystore.password = &quot;&quot; 
    
    # Maximum size of result set
    max-result-size = 50001
    
    # Cassandra driver connection pool settings
    # Documented at https://datastax.github.io/java-driver/features/pooling/
    connection-pool {

      # Create new connection threshold local
      new-connection-threshold-local = 800

      # Create new connection threshold remote
      new-connection-threshold-remote = 200

      # Connections per host core local
      connections-per-host-core-local = 1

      # Connections per host max local
      connections-per-host-max-local = 4

      # Connections per host core remote
      connections-per-host-core-remote = 1

      # Connections per host max remote
      connections-per-host-max-remote = 4

      # Max requests per connection local
      max-requests-per-connection-local = 32768

      # Max requests per connection remote
      max-requests-per-connection-remote = 2000

      # Sets the timeout when trying to acquire a connection from a host&#39;s pool
      pool-timeout-millis = 0
    }
    
    # Set the protocol version explicitly, should only be used for compatibility testing.
    # Supported values: 3, 4
    protocol-version = &quot;&quot;
    
  }

  # Exponential backoff for failures in CassandraReadSideProcessor    
  failure-exponential-backoff {
    # minimum (initial) duration until processor is started again
    # after failure
    min = 3s
    
    # the exponential back-off is capped to this duration
    max = 30s
    
    # additional random delay is based on this factor
    random-factor = 0.2
  }
  
  # The Akka dispatcher to use for read-side actors and tasks.
  use-dispatcher = &quot;lagom.persistence.dispatcher&quot;
}

lagom.defaults.persistence.read-side.cassandra {
	# Port of contact points in the Cassandra cluster
	port = 9042
	keyspace = &quot;lagom_read&quot;
}</code></pre><h2 id="Underlying-Implementation"><a class="section-marker" href="#Underlying-Implementation">§</a>Underlying Implementation</h2><p>The <code>CassandraSession</code> is using the <a href="https://github.com/datastax/java-driver">Datastax Java Driver for Apache Cassandra</a>.</p><p>Each <code>CassandraReadSideProcessor</code> instance is executed by an <a href="http://doc.akka.io/docs/akka/2.4.4/java/untyped-actors.html">Actor</a> that is managed by <a href="http://doc.akka.io/docs/akka/2.4.4/java/cluster-singleton.html">Akka Cluster Singleton</a>. The processor consumes a stream of persistent events delivered by the <code>eventsByTag</code> <a href="http://doc.akka.io/docs/akka/2.4.4/java/persistence-query.html">Persistence Query</a> implemented by <a href="https://github.com/akka/akka-persistence-cassandra">akka-persistence-cassandra</a>. The tag corresponds to the <code>tag</code> defined by the <code>AggregateEventTag</code>.</p><p>The <code>eventStream</code> of the <code>PersistentEntityRegistry</code> is also implemented by the <code>eventsByTag</code> query.</p>